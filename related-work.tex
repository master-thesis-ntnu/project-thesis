\chapter{Related Work}
\label{ch:related-work}
Currently there are research about query expansion and pseudo-relevance feedback.
Most of the research are focused towards achieving the best relevance,
while this project thesis focuses on making query expansion fast en scalable.

\section{Instant, Personalized Search Recommandation}
This project thesis is based on the work by Rudihagen \cite{master-thesis}.
His reseach focused on personalizing app recommandations to achieve better recommandations compared to returning the most popular results (popular meaning most downloaded).
The implemented recommandation engine returned promising results, but had a few shortcommings in terms of latency, scalability and test data size.

\begin{itemize}
  \item The implemented solution experienced a latency of up to 600 ms with some queries.
  \item Each user had their own index in Elasticsearch, which doesn't scale well.
  \item The dataset contained data from 46 different users.
\end{itemize}

This project thesis will explore the possibility to reduce the search latency to beneath the 100 ms mark, and how to structure data to scale better.
Based on the work by Rudihagen,
the implementation explaned in chapter \cite{ch:approach} assumes that pseudo-relevance feedback returns relevant results.

\section{Fuzzy Search}
With a standard term search the user has to spell the term correct, a misspelled term will most likely yield no or few results.
E.g the term "blu" should also retrieve results on the term "blue."
A studdy found that 50\% of users reformulate their queries, and close to a third of these users reformulated their query three times or more \cite{query-reformulate}.
To handle this problem a technique called fuzzy search may be used [Efficient Interactive Fuzzy Keyword Search].

A commonly used method with fuzzy search is Levenshtein distance.
Levenshtein distance calculates the number of characters edits which are required to transform one string into another.
Editting a string includes substitution, insertion and deletion.
Levenshtein distance can be expanded with the method Damerau to allow character transposition.

Elasticsearch uses Damerau-Levenshtein distance to calculate edit distance \footnote{\url{https://www.elastic.co/guide/en/elasticsearch/guide/current/fuzziness.html}}.
The Damerau-Levenshtein distance corresponds to the number of character edits.
A distance of 1, means one character has to be changed.

\section{Twitter Query Suggestion Engine}
\textit{Fast Data in the Era of Big Data: Twitter\'s Real-Time Related Query Suggestion Architecture} is a paper which describes the architecture behind Twitter's suggestion engine \cite{twitter-suggestion}.
One of the most important requirement for Twitter was to provide relevant search results within minutes of a event taking place.
More precicly they wanted to register trending hashtag within 10 minutes of a event happening.
Compared to this project thesis Twitter sees most popular within a given timeframe as relevant search results for the user.

\section{Pseudo-Relevance Feedback}
Pseudo-relevance feedback uses information from the top-k documents to compute query expansion terms.
However, the top-k documents is not always relevant and may introduce noise to the data set.
\textit{Query Dependent Pseudo-Relevance Feedback based on Wikipedia} research query dependent expansion on data from Wikipedia by using three different methods:
relevance model, strategy for entity/ambiguous queries and field evidence for query expansion \cite{pseudo-relevance-wikipedia}.
Their conclusion were that query dependent pseudo-relevance feedback can achieve better relevance compared to the baseline relevance model.
